{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing different basis blocks, along with their transform matrices\n",
    "stough 202-\n",
    "DIP Chapter 6, 8.9\n",
    "\n",
    "[Discrete wavelets](https://en.wikipedia.org/wiki/Discrete_wavelet_transform) broadly can be seen as a way of looking at a signal as a collection of patterns instead of as a collection of independent samples. In order to uniquely and fully describe a signal, these basis patterns should be orthogonal to one another (all dot products zero), have magnitude 1, and cover the space of all possible signals. For us, the signal is a NxN block of pixels within an image. [`wavelet_utils`](../dip_utils/wavelet_utils.py) provides numerous orthonormal basis sets for the block size of our choosing. Here, we look at them in turn. \n",
    "\n",
    "When I talk about the power of any basis, I am thinking of how efficient any such basis will be in terms of concentrating the signal in as few coefficients (basis patterns) as possible. This is also dependent on the kind of image data being considered. \n",
    "\n",
    "- [Markdown latex equations](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Typesetting%20Equations.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# For importing from alternative directory sources\n",
    "import sys  \n",
    "sys.path.insert(0, '../dip_utils')\n",
    "\n",
    "from matrix_utils import (arr_info,\n",
    "                          make_linmap)\n",
    "from vis_utils import (vis_image,\n",
    "                       vis_rgb_cube,\n",
    "                       vis_hists,\n",
    "                       vis_pair,\n",
    "                       vis_surface)\n",
    "\n",
    "from wavelet_utils import (make_haar_matrix,\n",
    "                           make_random_basis,\n",
    "                           make_klt_basis,\n",
    "                           make_dct_matrix,\n",
    "                           make_standard_matrix,\n",
    "                           vis_blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First up, the standard, or Euclidean matrix. \n",
    "This is the most natural basis, and the one you think about when you imagine a block to consist of a collection of pixels.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{H_{Euc}} =  \\begin{vmatrix}\n",
    "1 & 0 & 0 & 0\\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 1\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "If we consider just the 2D (2x2) version: \n",
    "\\begin{equation*}\n",
    "\\mathbf{H_{Euc}} =  \\begin{vmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1 \n",
    "\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "This is how you describe any location in a Cartesian 2D space. This is a basis pattern, where each coefficient will precisely reflect the signal in just one of the two pixels. Recall, these basis patterns should be orthogonal to one another, have magnitude 1, and cover the space of all possible signals. So \n",
    "\n",
    "- $\\langle 1,0 \\rangle \\cdot \\langle 0,1 \\rangle = 0$, so the basis is orthogonal\n",
    "- Each of $\\langle 1,0 \\rangle$ and $\\langle 0,1 \\rangle$ has magnitude 1 (square root of the sum of squares of the components). \n",
    "- We know every point in 2D can be described with a coordinate in x and a coordinate in y. Or, a coefficient with respect to $\\langle 1,0 \\rangle$ and a coefficient with respect to $\\langle 0,1 \\rangle$. \n",
    "\n",
    "We take outer products of the rows to extend this basis set to square-sized basis patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Euc = make_standard_matrix(4)\n",
    "vis_blocks(Euc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## Next up, the [Haar](https://en.wikipedia.org/wiki/Haar_wavelet) matrix. \n",
    "Most useful basis sets will account for spatial coherence by incorporating the mean as one of the basis vectors. If there is just one piece of information you can store about a block, the mean intensity of the block would be the first choice. The Haar basis construction can be found analytically in [DIP 6.9](https://gitlab.bucknell.edu/jvs008/dip365/blob/master/Readings/DIP_Wavelets_and_Haar.pdf), with the implementation details available to you in [waveletUtil.py](waveletUtil.py). \n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathbf{H_{Haar}} =  \\frac{1}{2}\\begin{vmatrix}\n",
    "1 & 1 & 1 & 1\\\\\n",
    "1 & 1 & -1 & -1 \\\\\n",
    "{\\sqrt 2} & -{\\sqrt 2} & 0 & 0 \\\\\n",
    "0 & 0 & {\\sqrt 2} & -{\\sqrt 2}\n",
    "\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "If we consider just the 2D (2x2) version: \n",
    "\\begin{equation*}\n",
    "\\mathbf{H_{Haar}} =  \\frac{1}{\\sqrt 2}\\begin{vmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & -1 \n",
    "\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "Rather than store a coefficient for each pixel as the Euclidean basis does, this seems to dedicate one coefficient to the average of the two pixels and one coefficient to difference between the two. This is also a basis pattern. Recall, these basis patterns should be orthogonal to one another, have magnitude 1, and cover the space of all possible signals. So \n",
    "\n",
    "- $\\langle \\frac{1}{\\sqrt 2}, \\frac{1}{\\sqrt 2} \\rangle \\cdot \\langle \\frac{1}{\\sqrt 2},-\\frac{1}{\\sqrt 2} \\rangle = 0$, so the basis is orthogonal\n",
    "- E.g.: $\\langle \\frac{1}{\\sqrt 2}, -\\frac{1}{\\sqrt 2} \\rangle$ has magnitude 1: $\\Bigl( \\frac{1}{\\sqrt 2} \\Bigr)^2 + \\Bigl( -\\frac{1}{\\sqrt 2} \\Bigr)^2 = 1$\n",
    "- The basis covers all possible signals, here points in 2D:  \n",
    "\\begin{equation*} \n",
    "\\forall (x,y) \\in R^2, \\verb+let+ \\\\\n",
    "a = \\langle \\frac{1}{\\sqrt 2}, \\frac{1}{\\sqrt 2} \\rangle \\cdot \\langle x,y \\rangle = \\frac{x + y}{\\sqrt 2}\\\\\n",
    "b = \\langle \\frac{1}{\\sqrt 2}, -\\frac{1}{\\sqrt 2} \\rangle \\cdot \\langle x,y \\rangle = \\frac{x - y}{\\sqrt 2}.\\\\\n",
    "\\verb+Then+ \\\\\n",
    "a\\langle \\frac{1}{\\sqrt 2}, \\frac{1}{\\sqrt 2} \\rangle + b\\langle \\frac{1}{\\sqrt 2}, -\\frac{1}{\\sqrt 2} \\rangle \\\\\n",
    "= \\Bigl( \\frac{x + y}{\\sqrt 2} \\Bigr)\\langle \\frac{1}{\\sqrt 2}, \\frac{1}{\\sqrt 2} \\rangle + \n",
    "\\Bigl( \\frac{x - y}{\\sqrt 2} \\Bigr)\\langle \\frac{1}{\\sqrt 2}, -\\frac{1}{\\sqrt 2} \\rangle \\\\\n",
    "= \\langle \\frac{x + y}{2}, \\frac{x + y}{2} \\rangle + \\langle \\frac{x - y}{2}, \\frac{-x + y}{2} \\rangle \\\\\n",
    "= \\langle \\frac{2x + y - y}{2}, \\frac{x - x + 2y}{2} \\rangle \\\\\n",
    "= \\langle x,y \\rangle\n",
    "\\end{equation*} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Haar = make_haar_matrix(4)\n",
    "vis_blocks(Haar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## Next up, the [Discrete Cosine transform](https://en.wikipedia.org/wiki/Discrete_cosine_transform) matrix. \n",
    "Each row of this matrix represents a sampled cosine wave with varying frequency over the signal space (s-D space, where s is the number of pixels). In that it satisfies the three conditions we specified above (left to you to prove), it can serve just as well as either of the above two. It is based in Fourier analysis on the idea that any signal can be constructed from [cosine and sine waveforms](https://www.physics.utoronto.ca/~vutha/405_teaching_materials/fourier_expansion_impedance.html).\n",
    "\n",
    "The DCT is even more powerful for natural images because unlike the above two, here every basis pattern extends over the whole block. In fact, [some form of DCT](https://epubs.siam.org/doi/pdf/10.1137/S0036144598336745) is usually so powerful, it has been adopted for use in [JPEG](https://en.wikipedia.org/wiki/JPEG), [MPEG](https://en.wikipedia.org/wiki/Moving_Picture_Experts_Group), and many other image and video compression standards.\n",
    "\n",
    "- [Syed Ali Khayam: The Discrete Cosine Transform (DCT): Theory and Application](https://gitlab.bucknell.edu/jvs008/dip365/blob/master/Readings/Khayam03_DCT_inDepth.pdf)\n",
    "- [R. J. Clarke, Image and Video Compression: A Survey](https://gitlab.bucknell.edu/jvs008/dip365/blob/master/Readings/Clarke99_ImageVideoCompressionSurvey.pdf)\n",
    "\n",
    "Recall $s$ is the number of pixels, i.e. the size of our square matrix. The first row is again the mean, while later rows ($u$) are sampled (by column $j$) cosines:\n",
    "\n",
    "\\begin{equation*} \n",
    "DCT_0 = \\sqrt \\frac{1}{s} \\\\\n",
    "DCT_u = \\sqrt \\frac{2}{s}cos\\Bigl(\\frac{(2j+1)u\\pi}{2s}\\Bigr), j = 0,\\dots,s-1, u = 1,\\dots,s-1\n",
    "\\end{equation*} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DCT = make_dct_matrix(4)\n",
    "print(DCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_blocks(DCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View some of these supposedly orthogonal vectors... \n",
    "DCT16 = make_dct_matrix(16)\n",
    "plt.figure()\n",
    "plt.plot(DCT16[:4,:].T)\n",
    "plt.legend(['row 0', 'row 1', 'row 2', 'row 3', 'row 4']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(DCT16[10,:], DCT16[5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(DCT16[3,:]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more detailed view of these basis patterns as height maps.\n",
    "DCT128 = make_dct_matrix(128) # So large just for visualization.\n",
    "vis_surface(np.outer(DCT128[2,:], DCT128[4,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## Random: with the magic of [Gram-Schmidt](https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process)\n",
    "orthonormalization, we can actually make a basis from any set of N vectors in N-D, as long as no one of them can be written as a linear combination of the others. There is of course no telling how powerful any such basis will be in terms of concentrating the signal in as few coefficients (basis patterns) as possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hrnd = make_random_basis(4)\n",
    "vis_blocks(Hrnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## Principal Component Analysis (PCA): \n",
    "Rather than either a predefined basis (e.g., Euclidean, Haar, DCT) or a random basis, let's make a basis that is ideal for the data that we want to compress. \n",
    "\n",
    "Principal components analysis is a much larger topic than we can cover just yet here, but if you're interested, take a look at this [youtube channel](https://www.youtube.com/playlist?list=PLbPhAbAhvjUzeLkPVnv0kc3_9rAfXpGtS). For us, PCA finds directions in the data space that account for the most variance in the data. That is, the first basis pattern PCA will compute is the one that accounts for as much of all the data differences as possible. After that, PCA will compute an orthogonal direction that accounts for as much of what's left as possible.\n",
    "\n",
    "- Here, and unlike the previous cases, we need the image data that we're interested in.\n",
    "- Unlike the predefined cases, we would have to explicitly send the transform matrix along with the coefficients to allow the receiving end to decode. This is like Huffman coding, where we construct just the right encoder/decoder to do the best job on the data at hand.\n",
    "- Using a pretty small size (like 4), PCA on many natural images will lead to a basis that bears some resemblance to DCT. This is congruent with what we have been told about the power of the DCT transform: on lots of natural images, the DCT is close to as good as it gets (which is PCA). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = plt.imread('../dip_pics/happy128.png').astype(np.float32)\n",
    "vis_image(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hpca = make_klt_basis(I, size=4)\n",
    "vis_blocks(Hpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the PCA ends up looking like a lot like the DCT. \n",
    "# That says something about the predefined DCT on natural images. \n",
    "f, ax = plt.subplots(4,8, figsize=(9,4))\n",
    "vis_blocks(DCT, ax[:,:4])\n",
    "vis_blocks(Hpca, ax[:,4:])\n",
    "ax[0][0].set_title('DCT');\n",
    "ax[0][4].set_title('PCA');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_surface(I[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
