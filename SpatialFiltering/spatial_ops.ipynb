{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Operations\n",
    "stough 202-\n",
    "\n",
    "1. [Predictive Coding from spatial operations perspective](#predictive)\n",
    "1. [Unsharp Masking](#unsharp) \n",
    "1. [Gradient Maps](#gradient)\n",
    "\n",
    "To this point we have generally thought of images as collections of **independent** pixels, organized in a grid for sure but not really thought of as a connected collection. We have heavily considered the [histograms of images](../NumpyAndVisualization/matplotlib_tutorial.ipynb#Histograms) for use in [contrast enhancement](../Enhancement/enhance_histeq.ipynb) and [compression](../Entropy/entropy_intro.ipynb), where histogramming completely destroys the spatial relationships that these pixels have with one another. In considering entropy in fact, we modeled our image as a sequence of **independent and identically distributed (iid)** symbols sampled from the histogram (probability distribution).\n",
    "\n",
    "We did hint at the importance of **spatial coherence**, which is exactly the way in which images are not iid sequences. We saw that **predictive coding**, using neighbors of a pixel to predict that pixel and then encoding only the error of prediction, leads to much more highly compressible signals than the images themselves. Were pixels iid, then such an encoding would be of no benefit. If our [power transform](../Enhancement/enhance_transfer.ipynb#power) is an example of a single-pixel operation (or point transform), then predictive coding is an example of a **spatial or neighborhood operation**.\n",
    "\n",
    "**Spatial operations** are operations that we apply to the pixels of an image that take into account the neighborhood of a pixel. Linear versions of such operations are also called **spatial filters**. We're basically looking at the neighborhood of a pixel and computing a linear combination of the values/intensities in that neighborhood. \n",
    "\n",
    "Here we're going to look at some spatial operations using [`scipy.ndimage.correlate`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.correlate.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "Bringing in [`scipy.ndimage.correlate`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.correlate.html) and [`convolve`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.convolve.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# For spatial filtering/operations\n",
    "from scipy.ndimage import (correlate,\n",
    "                           convolve)\n",
    "\n",
    "# For importing from alternative directory sources\n",
    "import sys  \n",
    "sys.path.insert(0, '../dip_utils')\n",
    "\n",
    "from matrix_utils import (arr_info,\n",
    "                          make_linmap)\n",
    "from vis_utils import (vis_rgb_cube,\n",
    "                       vis_hists,\n",
    "                       vis_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='predictive'></a>\n",
    "\n",
    "## Review Predictive Coding\n",
    "Instead of directly using `np.diff`, we can use correlate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = plt.imread('../dip_pics/canyon.jpg')\n",
    "vis_hists(I)\n",
    "print(arr_info(I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = I[...,0]\n",
    "vis_hists(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.array([-1, 1], ndmin=2).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_info(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jf = correlate(J.astype('int16'), h, mode='constant', cval=0)\n",
    "arr_info(Jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_hists(Jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='unsharp'></a>\n",
    "\n",
    "## Unsharp Masking\n",
    "Above we saw how to use a spatial filter to get at local pixel differences. \n",
    "Here we'll use a blur to actually sharpen the edges in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.ones((5,5))/25.0\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jf = correlate(J.astype('float'), h, mode='constant', cval=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_pair(J, Jf, cmap='gray', second_title=\"Blurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_info(Jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_info(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = J - Jf\n",
    "vis_hists(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_pair(J, D, cmap='gray', second_title='Original - Blurred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jsharp = J + 2*D \n",
    "# vis_pair(J, Jsharp, cmap='gray') # results in less contrast due to out-of-range pixels messing up display.\n",
    "vis_pair(J, np.clip(Jsharp,0,255), cmap='gray', second_title=\"Sharpened\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_info(Jsharp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(J[193, 250:270])\n",
    "plt.plot(np.clip(Jsharp,0,255)[193, 250:270])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gradient'></a>\n",
    "\n",
    "## Gradient Maps\n",
    "An alternative filter design can give us locally computed vertical and horizontal *edginess* if you will. These first order derivative images in $x,y$ can allow us to compute the gradient map of an image. Basically the edginess of every pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = plt.imread('../dip_pics/girl_with_glasses.png')\n",
    "vis_hists(I)\n",
    "print(arr_info(I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.ones((5,5))/25.0\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.array([[1, 0, -1],[2, 0, -2],[1, 0, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This filter we've designed above responds to vertical edges; that is, to get a large magnitude response from correlation with a 3x3 image neighborhood, we would need the left side of this tiny neighborhood to look brighter than the right (or darker for a large negative response). This is the famous Sobel operator, which you can read more about [here](https://en.wikipedia.org/wiki/Sobel_operator) and [here](https://homepages.inf.ed.ac.uk/rbf/HIPR2/sobel.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(h, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gx = correlate(I[...,0], h, mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_pair(I, Gx, cmap='gray', second_title=\"GX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gy = correlate(I[...,0], h.transpose(), mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_pair(Gx, Gy, cmap='gray', first_title='Gx', second_title='Gy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above are the first order derivatives in $x$ and $y$ for the original image when thought of as a height map, and using the Sobel operators to compute local difference. \n",
    "\n",
    "The gradient magnitude (how steep the height map is) is then the square root of the sum of the square dervatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = np.sqrt(Gx**2 + Gy**2)\n",
    "# G = Gx**2 + Gy**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_info(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_pair(I, G.max() - G, cmap='gray', second_title='Grad Mag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian\n",
    "second derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.array([[-1, -1, -1],[-1, 8, -1],[-1, -1, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = correlate(I[...,0], h, mode='nearest')\n",
    "arr_info(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = np.abs(J)\n",
    "J = J/J.max()\n",
    "arr_info(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_pair(I, 1 - np.log2(J+1),  cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
