{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using [torch](https://pytorch.org/docs/stable/cuda.html) to compare CPU/GPU speeds\n",
    "stough 202-\n",
    "\n",
    "The [Graphics Processing Unit](https://www.extremetech.com/gaming/269335-how-graphics-cards-work)\n",
    "is a common [coprocessor](https://en.wikipedia.org/wiki/Coprocessor) designed to do parallel floating point\n",
    "arithmetic. In the past this was computer graphics, but this massively parallel math is useful \n",
    "in all scientific computation.\n",
    "\n",
    "Also, going to use jupyterlab [magic commands](https://ipython.readthedocs.io/en/stable/interactive/magics.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.cuda as cuda\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.get_device_properties(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "## We'll do a large matrix multiply operation\n",
    "in numpy, torch, and torch on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.rand(400,1000,200)\n",
    "B = np.random.rand(400,200,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(8*A.size)/(1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.matmul(A,B)\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8*C.size/(1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 5 -r 4\n",
    "# C = np.matmul(A,B)\n",
    "np.matmul(A,B, out=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "### Test in Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "At_cpu = torch.from_numpy(A)\n",
    "Bt_cpu = torch.from_numpy(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "At_cpu.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ct_cpu = torch.matmul(At_cpu, Bt_cpu)\n",
    "Ct_cpu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 5 -r 4\n",
    "# Ct_cpu = torch.matmul(At_cpu, Bt_cpu)\n",
    "torch.matmul(At_cpu, Bt_cpu, out = Ct_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "### Now test in torch, on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "At_gpu = At_cpu.cuda()\n",
    "Bt_gpu = Bt_cpu.cuda()\n",
    "Ct_gpu = torch.zeros_like(Ct_cpu).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "At_gpu.is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 5 -r 4\n",
    "torch.matmul(At_gpu, Bt_gpu, out=Ct_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "### Try again, with our own timing.\n",
    "\n",
    "- [math expressions in markdown](https://stackoverflow.com/questions/48422762/is-it-possible-to-show-print-output-as-latex-in-jupyter-notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "for i in range(100):\n",
    "    torch.zeros(Ct_gpu.shape, out=Ct_gpu)\n",
    "    torch.matmul(At_gpu, Bt_gpu, out=Ct_gpu)\n",
    "    times.append(time.time() - st)\n",
    "\n",
    "et = time.time()\n",
    "\n",
    "# Why not be more complicated...\n",
    "# print(f'20 iters took {1000000*(et-st):.2f}')\n",
    "display(Markdown(rf'20 iters took {1000000*(et-st):.2f}$\\mu$s per.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
