{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look into the MNIST dataset with PyTorch.\n",
    "stough 202-\n",
    "\n",
    "The [MNIST database](https://en.wikipedia.org/wiki/MNIST_database) is one of the first large machine learning datasets, originally designed for the computer vision task of recognizing digits on bank checks. \n",
    "It consists of some {60000 training, 10000 test} 28x28 grayscale images of handwritten digits, along with each image's associated decimal digit represented. \n",
    "\n",
    "[PyTorch](https://pytorch.org/) is open source machine learning library principally developed by Facebook. It enables us to perform very advanced GPU-based machine learning through a convenient Python interface. \n",
    "\n",
    "We will here explore the MNIST dataset through PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import (Dataset,\n",
    "                              DataLoader)\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the training and test Datasets\n",
    "Torch allows us to interface with our data through [DataLoader and Dataset](https://pytorch.org/docs/stable/data.html#) objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thank you: https://www.aiworkbox.com/lessons/load-mnist-dataset-from-pytorch-torchvision\n",
    "# https://pytorch.org/docs/stable/torchvision/datasets.html\n",
    "mnist_trainset = datasets.MNIST(root='/home/dip365/data', train=True, download=False, transform=None, target_transform=None)\n",
    "mnist_testset = datasets.MNIST(root='/home/dip365/data', train=False, download=False, transform=None, target_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset[10000][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_tensor = ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = torch.stack([to_tensor(mnist_trainset[r][0]) \n",
    "                       for r in np.random.choice(len(mnist_trainset), 64, replace=False)])\n",
    "\n",
    "plt.imshow(make_grid(samples, nrow=8, pad_value=1.0).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at all training sevens.\n",
    "We do the permute because torch is channels-first, meaning each image is actually (1,28,28). \n",
    "If our images were color, the default orientation would be (3,h,w). This orientation is \n",
    "incompatible with matplotlib's `imshow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = torch.stack([to_tensor(mnist_trainset[r][0]) \n",
    "                       for r in range(len(mnist_trainset))\n",
    "                       if mnist_trainset[r][1]==7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,30))\n",
    "plt.imshow(make_grid(samples, nrow=70, pad_value=1.0).permute(1,2,0))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samples.numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.sum(samples, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
