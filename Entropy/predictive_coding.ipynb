{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Coding\n",
    "stough 202-\n",
    "\n",
    "In this notebook we're going to look at a way to account for very simple spatial redundancy, leading to much better compressibility. In short, a prediction of a pixel's value as its left neighbor is usually pretty effective, leading to a more compressible signal than the original without any loss of information. Read on for more.\n",
    "\n",
    "**Huffman**:\n",
    "In our discussion of [entropy](./entropy_intro.ipynb) we noted the different kinds of redundancy that we might leverage or account for in order to compress an image. We accounted for **coding redundancy** by applying Huffman variable length encoding. Huffman leverages differences in the relative probability of certain pixel values over others (low entropy) to define an encoding scheme that minimizes the average number of bits needed to represent each pixel value. Huffman's efficiency is inversely proportional to the entropy implied by the histogram of the image:\n",
    "- If the histogram tends toward uniform, entropy is high and Huffman coding will accomplish little.\n",
    "- If the histogram is highly non-uniform, with for example a few large spikes, then entropy is low and Huffman coding will work well.\n",
    "\n",
    "**Predictive coding** computes some derivation of the image: the value at every pixel is its difference with respect to the pixel to the left, with the first column not changing. We'll see that while this is a completely reversible function, such a predictive coded version of an image can be much more compressible that the original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# For spatial filtering/operations\n",
    "from scipy.ndimage import (correlate,\n",
    "                           convolve)\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# For importing from alternative directory sources\n",
    "import sys  \n",
    "sys.path.insert(0, '../dip_utils')\n",
    "\n",
    "from matrix_utils import (arr_info,\n",
    "                          make_linmap)\n",
    "from vis_utils import (vis_rgb_cube,\n",
    "                       vis_hists,\n",
    "                       vis_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = plt.imread('../dip_pics/skyandsea.jpg')\n",
    "vis_hists(I)\n",
    "print(arr_info(I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we're viewing the image in its original, human-readable form. Let's compute the entropy of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, bb = np.histogram(I.ravel(), bins = np.arange(257))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(freq, base=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe just one of the color channels, without loss of generality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = I[...,0]\n",
    "vis_hists(J)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using [`correlate`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.correlate.html) \n",
    "\n",
    "Here we're going to be using the `correlate` method in scipy in order to apply a simple linear function to neighborhoods of pixels. This *filtering* is a core element of image processing from simple edge-detection to convolutional neural networks, and we will be seeing it again and again. You should read more about filtering in the spatial domain [here](https://www.mathworks.com/help/images/what-is-image-filtering-in-the-spatial-domain.html).\n",
    "\n",
    "In this case the neighborhood in question is extremely simple. When our process is at a pixel $i,j$, then the neighorhood consists of that pixel and its neighbor to the left, $i,j-1$, or 0 if the pixel is at the left edge of the image already. The linear combination of the two pixels that we want to compute is just the difference. That is, $$p_{i,j}' = -1p_{i,j-1} + 1p_{i,j}$$\n",
    "We'll construct a simple array (also called a mask, or filter) that represents this linear combination, and then go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.array([-1, 1], ndmin=2).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_info(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jf = correlate(J.astype('int16'), h, mode='constant', cval=0)\n",
    "arr_info(Jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_hists(Jf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that if we take one pixel (value) and subtract another pixel from it, we may get a negative number. That's why in the above we consider the original image as `int16`, with both positive and negative possible values.\n",
    "\n",
    "Look at this image and its histogram compared to the one above. Which do you think has less entropy and therefore may be more highly compressible?\n",
    "\n",
    "I would like you to note as well that this operation is completely reversible; more on that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jf[:5, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J[:5,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jr = np.cumsum(Jf, axis=1)\n",
    "vis_hists(Jr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, bins = np.histogram(J.ravel(), bins=np.arange(257))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(freq, base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff, bb = np.histogram(Jf.ravel(), bins = np.arange(-255,257))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(ff, base=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Here we saw how predictive coding (filtering with that simple mask) is a completely reversible operation that leads to an image with significantly less entropy than the original image. Why is this? \n",
    "\n",
    "Basically, from what we've learned so far, images that are interesting to us generally contain large swaths of constant or smoothly-varying color or intensity changes. That is, most of the time the context of any pixel is highly predictive of that pixel's value itself. Where is this not the case? Really only at *edges*.  \n",
    "\n",
    "Since changes are smooth and small most of the time, the predictive-coded image will have many many more values close to zero, leading to a much more compressible distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
